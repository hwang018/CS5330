{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def eucl_dist(a, b, axis=1):\n",
    "    return np.linalg.norm(a - b, axis=axis)\n",
    "\n",
    "def get_center(k, X):\n",
    "    temp = []\n",
    "    #first center is appended here\n",
    "    \n",
    "    temp.append(X[np.random.randint(0, len(X))])\n",
    "    \n",
    "    \n",
    "    while len(temp)<k:\n",
    "        d2 = np.array([min([np.square(eucl_dist(i,c, None)) for c in temp]) for i in X])\n",
    "        prob = d2/d2.sum()\n",
    "        cum_prob = prob.cumsum()\n",
    "        r = np.random.random()\n",
    "        ind = np.where(cum_prob >= r)[0][0]\n",
    "        temp.append(X[ind])\n",
    "    return np.array(temp)\n",
    "\n",
    "def k_mean_pp(x, k):\n",
    "    # error = {key:0.0 for key in range(2,11)}\n",
    "    # initalizing cluster variable\n",
    "    center = get_center(k, x)\n",
    "    # for k in range(2,11):\n",
    "    # assigining zeros to old centroids value\n",
    "    center_old = np.zeros(center.shape)\n",
    "    # initial error\n",
    "    err = eucl_dist(center, center_old, None)\n",
    "\n",
    "    cluster = {}\n",
    "    \n",
    "    while err != 0:\n",
    "        # calculatin distance of data points from centroids and assiging min distance cluster centroid as data point cluster\n",
    "        for i in range(len(x)):\n",
    "            distances = eucl_dist(x[i], center)\n",
    "            clust = np.argmin(distances)\n",
    "            cluster[i] = clust\n",
    "        # changing old centroids value\n",
    "        center_old = np.copy(center)\n",
    "\n",
    "        # Finding the new centroids by taking the average value\n",
    "        for i in range(k):\n",
    "            points = [x[j] for j in range(len(x)) if cluster[j] == i]\n",
    "            if points:\n",
    "                center[i] = np.mean(points, axis=0)\n",
    "\n",
    "        # calculation difference between new centroid and old centroid values\n",
    "        err = eucl_dist(center, center_old, None)\n",
    "\n",
    "    # calculation total difference between cluster centroids and cluster data points\n",
    "    error = 0\n",
    "    for i in range(k):\n",
    "        d = [eucl_dist(x[j], center[i], None) for j in range(len(x)) if cluster[j] == i]\n",
    "        error += np.sum(d)\n",
    "\n",
    "    # counting data points in all clusters\n",
    "    count = {key: 0.0 for key in range(k)}\n",
    "    for i in range(len(x)):\n",
    "        count[cluster[i]] += 1\n",
    "\n",
    "    # displaying cluster number, average distance between centroids and data points and cluster count\n",
    "    print(k, error / len(x), count)\n",
    "\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-afe362b4f52d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'sepal length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sepal width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'petal length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'petal width'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Separating out the features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Separating out the target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "features = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "# Separating out the features\n",
    "x = df.loc[:, features].values\n",
    "# Separating out the target\n",
    "y = df.loc[:,['target']].values\n",
    "# Standardizing the features\n",
    "x = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf = pd.concat([principalDf, df[['target']]], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset of form [[data1],[data2], ....]\n",
    "inp = pickle.load(open('test.pickle', 'rb'))\n",
    "x = np.array([i[0] for i in inp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 73,  67,  66,  77,  32,  73, 110,  32]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_center(1,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 26.095815406758355 {0: 152.0, 1: 20.0, 2: 47.0, 3: 32.0, 4: 374.0, 5: 88.0, 6: 166.0, 7: 2.0, 8: 89.0, 9: 30.0}\n"
     ]
    }
   ],
   "source": [
    "abc = k_mean_pp(x,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # loading dataset of form [[data1],[data2], ....]\n",
    "    inp = pickle.load(open('test.pickle', 'rb'))\n",
    "    x = np.array([i[0] for i in inp])\n",
    "\n",
    "    # return cluster number for every data\n",
    "    cluster = k_mean_pp(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
